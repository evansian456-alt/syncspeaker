<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width,initial-scale=1">
  <title>SyncSpeaker — demo</title>

  <style>
    * { margin: 0; padding: 0; box-sizing: border-box; }
    body {
      font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
      background: #000;
      color: #fff;
      min-height: 100vh;
      line-height: 1.6;
      padding: 20px;
    }

    .bg {
      position: fixed;
      inset: 0;
      background:
        radial-gradient(circle at 20% 20%, rgba(100,50,200,0.15), transparent 40%),
        radial-gradient(circle at 80% 80%, rgba(50,150,200,0.12), transparent 40%),
        linear-gradient(180deg, #0a0a0a 0%, #000 100%);
      z-index: -1;
    }

    .container {
      max-width: 700px;
      margin: 0 auto;
      padding-top: 2rem;
    }

    .header {
      text-align: center;
      margin-bottom: 2rem;
    }

    h1 {
      font-size: clamp(2rem, 5vw, 3rem);
      margin-bottom: 0.5rem;
      background: linear-gradient(135deg, #6dd5ed, #2193b0);
      background-clip: text;
      -webkit-background-clip: text;
      -webkit-text-fill-color: transparent;
      font-weight: 700;
    }

    .lead {
      color: #aaa;
      font-size: 1.1rem;
    }

    .controls {
      display: flex;
      gap: 10px;
      justify-content: center;
      flex-wrap: wrap;
      margin: 1.5rem 0;
    }

    button {
      background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
      color: white;
      border: none;
      padding: 12px 24px;
      border-radius: 6px;
      cursor: pointer;
      font-size: 1rem;
      font-weight: 600;
      transition: transform 0.2s, box-shadow 0.2s;
    }

    button:hover {
      transform: translateY(-2px);
      box-shadow: 0 4px 12px rgba(102, 126, 234, 0.4);
    }

    button:active {
      transform: translateY(0);
    }

    button.secondary {
      background: transparent;
      border: 1px solid rgba(255,255,255,0.2);
      color: #ddd;
    }

    button.secondary:hover {
      border-color: rgba(255,255,255,0.4);
      box-shadow: 0 4px 12px rgba(255, 255, 255, 0.1);
    }

    #captions {
      background: rgba(255,255,255,0.05);
      border: 1px solid rgba(255,255,255,0.1);
      border-radius: 8px;
      padding: 1rem;
      margin: 1.5rem 0;
      min-height: 60px;
      text-align: center;
      font-size: 1.05rem;
      color: #eee;
    }

    #status {
      text-align: center;
      font-size: 0.95rem;
    }

    footer {
      text-align: center;
      margin-top: 3rem;
      padding-top: 2rem;
      border-top: 1px solid rgba(255,255,255,0.1);
      color: #777;
      font-size: 0.9rem;
    }

    @media (max-width: 600px) {
      .container {
        padding-top: 1rem;
      }
      button {
        padding: 10px 18px;
        font-size: 0.95rem;
      }
    }
  </style>
</head>
<body>

  <div class="bg" aria-hidden="true"></div>

  <main class="container" role="main">
    <header class="header">
      <h1>SyncSpeaker</h1>
      <p class="lead">Synchronize audio and captions — demo page.</p>
    </header>

    <section class="controls" aria-label="Controls">
      <button id="playBtn" aria-controls="sampleAudio">Play sample</button>
      <button id="pauseBtn" class="secondary" aria-controls="sampleAudio">Pause</button>
      <button id="stopBtn" class="secondary" aria-controls="sampleAudio">Stop</button>
    </section>

    <!-- Audio element: replace the src with your actual audio file (sample.mp3)
         A captions file (WebVTT) can be added as captions.vtt; it's optional.
         If no audio file is bundled, the page falls back to a short demo tone. -->
    <audio id="sampleAudio" preload="none">
      <!-- Example: <source src="assets/sample.mp3" type="audio/mpeg"> -->
      <!-- Captions track (optional): create captions.vtt and uncomment below -->
      <!-- <track id="enTrack" kind="captions" srclang="en" label="English" src="captions.vtt" default> -->
      Your browser does not support the audio element.
    </audio>

    <div id="captions" aria-live="polite" aria-atomic="true">Captions will appear here.</div>
    <section id="status" aria-live="polite" style="margin-top:12px; color:#99aaaa;">
      Ready.
    </section>

    <footer>
      <small>&copy; 2026 SyncSpeaker — local demo</small>
    </footer>
  </main>

  <script>
    // Accessible, minimal playback + captions wiring.
    (function () {
      const playBtn = document.getElementById('playBtn');
      const pauseBtn = document.getElementById('pauseBtn');
      const stopBtn = document.getElementById('stopBtn');
      const status = document.getElementById('status');
      const captionsBox = document.getElementById('captions');
      const audio = document.getElementById('sampleAudio');

      // Track playback state for UI
      let isUsingOscillator = false;
      let audioCtx, oscillator, oscGain;

      function supportsAudioSrc() {
        // Return true if an audio src was added (<source> or audio.src)
        // audio.currentSrc will be non-empty when a source is present and selected.
        return Boolean(audio.currentSrc || audio.querySelector('source'));
      }

      function startOscillatorDemo() {
        // Fallback short tone if no audio file is bundled
        if (isUsingOscillator) return; // Prevent multiple oscillators
        if (!audioCtx) {
          audioCtx = new (window.AudioContext || window.webkitAudioContext)();
        }
        oscillator = audioCtx.createOscillator();
        oscGain = audioCtx.createGain();
        oscillator.type = 'sine';
        oscillator.frequency.value = 440;
        oscGain.gain.value = 0.0001; // start very quiet to avoid click
        oscillator.connect(oscGain);
        oscGain.connect(audioCtx.destination);
        oscillator.start();
        // ramp up, play for up to 30s (or until stopped)
        oscGain.gain.linearRampToValueAtTime(0.12, audioCtx.currentTime + 0.02);
        isUsingOscillator = true;
        status.textContent = 'Playing demo tone (no audio bundled).';
        captionsBox.textContent = '[Demo tone — no captions available]';
      }

      function stopOscillatorDemo() {
        if (!isUsingOscillator || !oscillator) return;
        oscGain.gain.linearRampToValueAtTime(0.0001, audioCtx.currentTime + 0.02);
        const oscToStop = oscillator;
        const gainToStop = oscGain;
        setTimeout(() => {
          try { oscToStop.stop(); } catch (e) { /* ignore */ }
          oscToStop.disconnect();
          gainToStop.disconnect();
        }, 50);
        oscillator = null;
        oscGain = null;
        isUsingOscillator = false;
      }

      // Wire play/pause/stop
      playBtn.addEventListener('click', async () => {
        try {
          if (supportsAudioSrc()) {
            await audio.play();
            status.textContent = 'Playing.';
          } else {
            // No source provided: use WebAudio demo tone
            startOscillatorDemo();
          }
        } catch (err) {
          status.textContent = 'Playback blocked — user interaction required.';
        }
      });

      pauseBtn.addEventListener('click', () => {
        if (isUsingOscillator) {
          // Stop tone but keep ability to restart
          stopOscillatorDemo();
          status.textContent = 'Paused (demo tone).';
        } else if (supportsAudioSrc()) {
          audio.pause();
          status.textContent = 'Paused.';
        } else {
          status.textContent = 'Nothing to pause.';
        }
      });

      stopBtn.addEventListener('click', () => {
        if (isUsingOscillator) {
          stopOscillatorDemo();
          status.textContent = 'Stopped (demo tone).';
          captionsBox.textContent = 'Captions will appear here.';
        } else if (supportsAudioSrc()) {
          audio.pause();
          audio.currentTime = 0;
          status.textContent = 'Stopped.';
          captionsBox.textContent = 'Captions will appear here.';
        } else {
          status.textContent = 'Nothing to stop.';
        }
      });

      // Keyboard: allow Space/Enter to activate buttons when focused (native for <button>)
      // Captions: if a WebVTT track is provided, display cues here.
      function setupCaptions() {
        // textTracks may not be ready until the track is loaded; use a short timeout to attach.
        const tracks = audio.textTracks;
        if (!tracks || tracks.length === 0) {
          // No tracks declared — show placeholder.
          captionsBox.textContent = 'No captions available.';
          return;
        }

        // Use first text track
        const tt = tracks[0];
        tt.mode = 'hidden'; // keep it from automatically showing browser UI
        // When cue changes, update our caption box
        tt.addEventListener('cuechange', () => {
          const active = tt.activeCues;
          if (active && active.length) {
            const texts = [];
            for (let i = 0; i < active.length; i++) {
              texts.push(active[i].text);
            }
            captionsBox.textContent = texts.join(' ');
          } else {
            captionsBox.textContent = '';
          }
        });
      }

      // If a source or track might be added later, attempt to initialize captions on load.
      audio.addEventListener('loadedmetadata', setupCaptions, { once: true });
      // Also try after DOM load (for static tracks)
      document.addEventListener('DOMContentLoaded', () => {
        setTimeout(setupCaptions, 50);
      });

      // Clean up audio context on page unload (good practice)
      window.addEventListener('beforeunload', () => {
        if (audioCtx && typeof audioCtx.close === 'function') audioCtx.close();
      });
    })();
  </script>

</body>
</html>
