<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width,initial-scale=1">
  <title>SyncSpeaker — demo</title>

  <style>
    * { margin:0; padding:0; box-sizing:border-box; }
    body {
      font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
      background: #000;
      color: #fff;
      min-height: 100vh;
      text-align: center;
      padding: 20px;
      line-height: 1.6;
    }

    /* Background gradient */
    .bg {
      position: fixed;
      inset: 0;
      background:
        radial-gradient(circle at 10% 10%, rgba(255,255,255,0.04), rgba(255,255,255,0) 22%),
        linear-gradient(180deg, #0a0a0a 0%, #000 60%);
      z-index: -1;
    }

    .container {
      max-width: 760px;
      margin: 0 auto;
      padding-top: 40px;
    }

    .header {
      margin-bottom: 24px;
    }

    h1 {
      font-size: clamp(2rem, 5vw, 3rem);
      letter-spacing: 1px;
      margin-bottom: 8px;
      font-weight: 600;
    }

    p.lead {
      color: #ccc;
      font-size: 1rem;
      font-weight: 300;
    }

    .controls {
      margin: 24px 0;
      display: flex;
      gap: 10px;
      justify-content: center;
      flex-wrap: wrap;
    }

    button {
      background: linear-gradient(135deg, #4a90e2, #357abd);
      color: white;
      border: none;
      padding: 10px 18px;
      border-radius: 6px;
      cursor: pointer;
      font-size: 0.95rem;
      font-weight: 600;
      transition: transform 0.1s, box-shadow 0.2s;
    }
    button:hover { transform: translateY(-1px); box-shadow: 0 4px 12px rgba(74,144,226,0.4); }
    button:active { transform: translateY(0); }
    button:focus { outline: 2px solid #4a90e2; outline-offset: 2px; }

    button.secondary {
      background: transparent;
      border: 1px solid rgba(255,255,255,0.2);
      color: #ddd;
    }
    button.secondary:hover { border-color: rgba(255,255,255,0.4); box-shadow: 0 2px 8px rgba(255,255,255,0.1); }

    #captions {
      margin-top: 20px;
      padding: 16px 20px;
      background: rgba(255,255,255,0.05);
      border-radius: 8px;
      min-height: 60px;
      font-size: 1.05rem;
      color: #f5f5f5;
      border: 1px solid rgba(255,255,255,0.08);
    }

    footer {
      margin-top: 40px;
      color: #888;
      font-size: 0.85rem;
    }

    @media (max-width: 480px) {
      .container { padding-top: 20px; }
      button { padding: 9px 14px; font-size: 0.9rem; }
    }
  </style>
</head>
<body>

  <div class="bg" aria-hidden="true"></div>

  <main class="container" role="main">
    <header class="header">
      <h1>SyncSpeaker</h1>
      <p class="lead">Synchronize audio and captions — demo page.</p>
    </header>

    <section class="controls" aria-label="Controls">
      <button id="playBtn" aria-controls="sampleAudio">Play sample</button>
      <button id="pauseBtn" class="secondary" aria-controls="sampleAudio">Pause</button>
      <button id="stopBtn" class="secondary" aria-controls="sampleAudio">Stop</button>
    </section>

    <!-- Audio element with sample audio file and synchronized captions -->
    <audio id="sampleAudio" preload="metadata">
      <source src="assets/sample.mp3" type="audio/mpeg">
      <track id="enTrack" kind="captions" srclang="en" label="English" src="assets/captions.vtt" default>
      Your browser does not support the audio element.
    </audio>

    <div id="captions" aria-live="polite" aria-atomic="true">Captions will appear here.</div>
    <section id="status" aria-live="polite" style="margin-top:12px; color:#9aa;">
      Ready.
    </section>

    <footer>
      <small>&copy; 2026 SyncSpeaker — local demo</small>
    </footer>
  </main>

  <script>
    // Accessible, minimal playback + captions wiring.
    (function () {
      const playBtn = document.getElementById('playBtn');
      const pauseBtn = document.getElementById('pauseBtn');
      const stopBtn = document.getElementById('stopBtn');
      const status = document.getElementById('status');
      const captionsBox = document.getElementById('captions');
      const audio = document.getElementById('sampleAudio');

      // Track playback state for UI
      let isUsingOscillator = false;
      let audioCtx, oscillator, oscGain;

      function supportsAudioSrc() {
        // Return true if an audio src was added (<source> or audio.src)
        // audio.currentSrc will be non-empty when a source is present and selected.
        return Boolean(audio.currentSrc || audio.querySelector('source'));
      }

      function startOscillatorDemo() {
        // Fallback short tone if no audio file is bundled
        if (!audioCtx) {
          audioCtx = new (window.AudioContext || window.webkitAudioContext)();
        }
        oscillator = audioCtx.createOscillator();
        oscGain = audioCtx.createGain();
        oscillator.type = 'sine';
        oscillator.frequency.value = 440;
        oscGain.gain.value = 0.0001; // start very quiet to avoid click
        oscillator.connect(oscGain);
        oscGain.connect(audioCtx.destination);
        oscillator.start();
        // ramp up, play for up to 30s (or until stopped)
        oscGain.gain.linearRampToValueAtTime(0.12, audioCtx.currentTime + 0.02);
        isUsingOscillator = true;
        status.textContent = 'Playing demo tone (no audio bundled).';
        captionsBox.textContent = '[Demo tone — no captions available]';
      }

      function stopOscillatorDemo() {
        if (!isUsingOscillator || !oscillator) return;
        oscGain.gain.linearRampToValueAtTime(0.0001, audioCtx.currentTime + 0.02);
        setTimeout(() => {
          try { oscillator.stop(); } catch (e) { /* ignore */ }
          oscillator.disconnect();
          oscGain.disconnect();
        }, 50);
        oscillator = null;
        oscGain = null;
        isUsingOscillator = false;
      }

      // Wire play/pause/stop
      playBtn.addEventListener('click', async () => {
        try {
          if (supportsAudioSrc()) {
            await audio.play();
            status.textContent = 'Playing.';
          } else {
            // No source provided: use WebAudio demo tone
            startOscillatorDemo();
          }
        } catch (err) {
          status.textContent = 'Playback blocked — user interaction required.';
        }
      });

      pauseBtn.addEventListener('click', () => {
        if (isUsingOscillator) {
          // Stop tone but keep ability to restart
          stopOscillatorDemo();
          status.textContent = 'Paused (demo tone).';
        } else if (supportsAudioSrc()) {
          audio.pause();
          status.textContent = 'Paused.';
        } else {
          status.textContent = 'Nothing to pause.';
        }
      });

      stopBtn.addEventListener('click', () => {
        if (isUsingOscillator) {
          stopOscillatorDemo();
          status.textContent = 'Stopped (demo tone).';
          captionsBox.textContent = 'Captions will appear here.';
        } else if (supportsAudioSrc()) {
          audio.pause();
          audio.currentTime = 0;
          status.textContent = 'Stopped.';
          captionsBox.textContent = 'Captions will appear here.';
        } else {
          status.textContent = 'Nothing to stop.';
        }
      });

      // Keyboard: allow Space/Enter to activate buttons when focused (native for <button>)
      // Captions: if a WebVTT track is provided, display cues here.
      function setupCaptions() {
        // textTracks may not be ready until the track is loaded; use a short timeout to attach.
        const tracks = audio.textTracks;
        if (!tracks || tracks.length === 0) {
          // No tracks declared — show placeholder.
          captionsBox.textContent = 'No captions available.';
          return;
        }

        // Use first text track
        const tt = tracks[0];
        tt.mode = 'hidden'; // keep it from automatically showing browser UI
        // When cue changes, update our caption box
        tt.addEventListener('cuechange', () => {
          const active = tt.activeCues;
          if (active && active.length) {
            const texts = [];
            for (let i = 0; i < active.length; i++) {
              texts.push(active[i].text);
            }
            captionsBox.textContent = texts.join(' ');
          } else {
            captionsBox.textContent = '';
          }
        });
      }

      // If a source or track might be added later, attempt to initialize captions on load.
      audio.addEventListener('loadedmetadata', setupCaptions, { once: true });
      // Also try after DOM load (for static tracks)
      document.addEventListener('DOMContentLoaded', () => {
        setTimeout(setupCaptions, 50);
      });

      // Clean up audio context on page unload (good practice)
      window.addEventListener('beforeunload', () => {
        if (audioCtx && typeof audioCtx.close === 'function') audioCtx.close();
      });
    })();
  </script>

</body>
</html>
